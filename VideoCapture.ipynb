{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets install some image utilities\n",
    "! pip install ipympl\n",
    "\n",
    "# Core imports for the notebook\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# We will use the ResNet50 Keras model, pre-trained with imagenet weights...\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# ResNet50 helpers used specifically with our selected pre-trained model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "! pip install pelion_sagemaker_controller\n",
    "from pelion_sagemaker_controller import pelion_sagemaker_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration settings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS Tunables\n",
    "aws_region = 'us-east-1'\n",
    "aws_s3_folder = \"demo-sagemaker-edge\"     # Root directory to be used in our S3 bucket\n",
    "\n",
    "# We will use the ResNet50 image recognition model via Keras framework\n",
    "model_framework = 'keras'\n",
    "model_basename = 'resnet50'\n",
    "model_name = model_framework + \"-\" + model_basename + \"-image-recognizer\"\n",
    "packaged_model_name = model_framework + \"-\" + model_basename + \"-model\"\n",
    "packaged_model_version = \"1.0\"\n",
    "model_package = '{}-{}.tar.gz'.format(packaged_model_name, packaged_model_version)\n",
    "model_max_input_key = packaged_model_name + \"-max-num-inputs\"\n",
    "model_max_input_key = model_max_input_key.replace('-','_')\n",
    "\n",
    "# These typically dont need to be changed... \n",
    "endpoint_api = 'api.' + aws_region + '.mbedcloud.com'              # This is optional and the default\n",
    "async_response_sec = 0.25                                          # Pelion long polling tunable. Typically no need to change\n",
    "busy_loop_wait_time_sec = 0.5                                      # This is our busy loop polling interval. Typically no need to change\n",
    "\n",
    "# Decoder classification json specific to ResNet50...\n",
    "resnet50_class_list_path = './model/imagenet_class_index.json'\n",
    "\n",
    "# Number of images to capture in a single iteration\n",
    "max_num_images       = 1\n",
    "vp_capture_fps_ms    = 3000\n",
    "\n",
    "# Input images WxH is 224x224 and are color images (so 3 channels)\n",
    "image_size_w         = 224\n",
    "image_size_h         = 224\n",
    "image_num_channels   = 3\n",
    "\n",
    "# Expected shape\n",
    "vp_shape = {\"width\":image_size_w, \"height\":image_size_h, \"depth\":image_num_channels}\n",
    "\n",
    "# capture loop sleep times (in seconds)\n",
    "vp_initial_sleep_sec = 5\n",
    "vp_loop_sleep_sec    = 3\n",
    "vp_clean_sleep_sec   = 3\n",
    "\n",
    "# Post-display capture clearing\n",
    "vp_clear_s3          = True    # Clear out the captures from S3 bucket\n",
    "vp_clear_nb          = True    # Clear out the captures from our Notebook\n",
    "\n",
    "# Our Notebok directory where captures are stored\n",
    "vp_np_capture_dir    = \"capture\"\n",
    "\n",
    "# Our Pelion Edge Gateway is a Nvidia Jetson Xavier\n",
    "target_device        = 'jetson_xavier'\n",
    "\n",
    "# Set our Pelion API Configuration Here\n",
    "api_key   = 'INSERT_YOUR_PELION_APPLICATION_KEY_HERE'\n",
    "device_id = 'INSERT_YOUR_PELION_XAVIER_EDGE_SAGE_PT_DEVICEID_HERE'                            # Pelion Device ID of our Sagemaker Edge Agent PT device under our Pelion Edge gateway\n",
    "video_processor_device_id = 'INSERT_YOUR_PELION_XAVIER_EDGE_VIDEO_PROCESSOR_PT_DEVICEID_HERE' # Pelion Device ID of our Video Processor PT\n",
    "\n",
    "# Dougs API Key and Sagemaker Edge Agent Manager PT DeviceID + Video Processor PT DeviceID\n",
    "api_key                   = 'ak_2MDE2ZmZjZmQwOTgxNGE2OGYxNmFlODQ0MDAwMDAwMDA0176d3f035509609f897638900000000Negxfm3p2PwYYEkqN1VKjqxMlM07HOzA'\n",
    "device_id                 = '017a415e4fb83230f97c93d800300000'\n",
    "video_processor_device_id = '017cddbbdd92d611df6b7d3700300000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocate our Notebook client API and set its configuration - including the Video Processor extensions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Allocating Notebook Client API and setting configuration...\")\n",
    "my_notebook = pelion_sagemaker_controller.MyNotebook(api_key, device_id, endpoint_api, aws_s3_folder, async_response_sec)\n",
    "\n",
    "#\n",
    "# IMPORTANT: set the compiled # input images from our first input data set...\n",
    "#\n",
    "# NOTE:  While it appears that you can feed your compiled model more or less than this value,\n",
    "#        the FIRST execution of your model MUST contain exactly this many inputs... otherwise\n",
    "#        Sagemaker Edge Agent Manager will crash and you will have to reboot your gateway.\n",
    "#       \n",
    "#        Subsequent invocations will work fine with fewer inputs... invoacations with larger\n",
    "#        inputs will also complete, however you will only receive predictions for the first \n",
    "#        \"max_compiled_model_num_input_images\" inputs - the others will not have predictions. \n",
    "#\n",
    "#        In future notebooks/versions, we'll be using this configuration entry.\n",
    "#\n",
    "my_notebook.pelion_api.pelion_set_config(model_max_input_key,max_num_images)\n",
    "max_compiled_model_num_input_images = my_notebook.pelion_api.pelion_get_config(model_max_input_key)\n",
    "print(\"\")\n",
    "print(\"Setting max number of input images for our compiled ResNet50 model (\" + model_max_input_key + \") to: \" + str(max_compiled_model_num_input_images))\n",
    "\n",
    "# Compile up for our target Pelion Edge Gateway platform type\n",
    "print(\"\")\n",
    "print(\"Initiating Sagemaker Neo compile of \" + model_name + \"...\")\n",
    "# job_name = my_notebook.compile_model(resnet50_model, target_device, model_basename, model_framework, neo_input_layer_shape)\n",
    "\n",
    "# Package up and store the compiled model onto S3\n",
    "print(\"\")\n",
    "print(\"Packaging up Neo-compiled model and placing in S3...\")\n",
    "# model_package = my_notebook.package_model(packaged_model_name, packaged_model_version, job_name)\n",
    "print(\"\")\n",
    "print(\"Model Package: \" + model_package)\n",
    "\n",
    "#\n",
    "# Add the deviceID for our VideoProcessor PT\n",
    "#\n",
    "print(\"\")\n",
    "print(\"Setting video processor PT device ID: \" + video_processor_device_id)\n",
    "my_notebook.pelion_api.setVideoProcessorDeviceID(video_processor_device_id);\n",
    "\n",
    "#\n",
    "# Establish configuration for the VideoProcessor\n",
    "#\n",
    "print(\"\")\n",
    "print(\"Setting video processor extension configuration...\")\n",
    "my_notebook.vp_set_captures_per_iteration(max_num_images)\n",
    "my_notebook.vp_set_capture_directory(vp_np_capture_dir)\n",
    "my_notebook.pelion_api.pelion_set_vp_config(\"captureFPS\",str(vp_capture_fps_ms))\n",
    "my_notebook.pelion_api.pelion_set_vp_config(\"model\",model_name)\n",
    "my_notebook.pelion_api.pelion_set_vp_config(\"shape\",json.dumps(vp_shape))\n",
    "\n",
    "# Get the VP configuration\n",
    "vp_config = my_notebook.pelion_api.pelion_get_vp_config()\n",
    "print(\"\")\n",
    "print(\"Video Processor Extension Configuration:\")\n",
    "print(vp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our Keras50 model with the default ImageNet weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Allocating ResNet50 model\")\n",
    "resnet50_model = ResNet50(weights=\"imagenet\", pooling=\"avg\")\n",
    "    \n",
    "# Lets dump the model details... \n",
    "print(resnet50_model.summary())\n",
    "\n",
    "# Next, lets record the input layer for the Neo-compatible input_shape for Keras-based models...\n",
    "input_layer = resnet50_model.get_layer(index=0)\n",
    "\n",
    "# Neo wants me to build out a specific input_shape (in NCHW per above...) for the compile() task...\n",
    "neo_input_layer_shape = {}\n",
    "neo_input_layer_shape[input_layer.name] = [max_compiled_model_num_input_images, image_num_channels, image_size_h, image_size_w]\n",
    "neo_input_layer_shape = json.dumps(neo_input_layer_shape)\n",
    "print(\"\")\n",
    "print(\"Neo expects this input_shape if compiling a Keras model: \" + neo_input_layer_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and package up the model using Neo (long-winded...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Initiating Sagemaker Neo compile of \" + model_name + \" for platfrorm: \" + target_device + \"...\")\n",
    "job_name = my_notebook.compile_model(resnet50_model, target_device, model_basename, model_framework, neo_input_layer_shape)\n",
    "\n",
    "# Package up and store the compiled model onto S3\n",
    "print(\"\")\n",
    "print(\"Packaging up Neo-compiled model and placing in S3...\")\n",
    "model_package = my_notebook.package_model(packaged_model_name, packaged_model_version, job_name)\n",
    "print(\"\")\n",
    "print(\"Model Package: \" + model_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the newly compiled model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print('Reloading Model: ' + model_name + \" in package: \" + model_package + '...')\n",
    "print(\"\")\n",
    "my_notebook.pelion_api.pelion_reload_model(model_name,model_package)\n",
    "\n",
    "# Poll every 5 sec to look for the reload() completion....\n",
    "while True:\n",
    "    print(\"Reloading \" + model_name + \"...\")\n",
    "    is_running = my_notebook.pelion_api.pelion_cmd_is_running(\"reloadModel\");\n",
    "    if is_running == False:\n",
    "        print(\"\")\n",
    "        print('Reload Completed!')\n",
    "        print(\"\")\n",
    "        break\n",
    "    time.sleep(5)\n",
    "    \n",
    "# Get the loaded model info via Pelion...\n",
    "time.sleep(5)\n",
    "reload_result = my_notebook.pelion_api.pelion_list_models();\n",
    "if 'response' in reload_result and len(reload_result['response']) > 0:\n",
    "    if 'name' in reload_result['response'][0]:\n",
    "        print(\"\")\n",
    "        print(\"Currently Loaded Model(s):\")\n",
    "        print(reload_result)\n",
    "else:\n",
    "    print(\"Model: \" + model_name + \" did NOT load properly. Check sagemaker edge agent logs on GW.\")\n",
    "\n",
    "    \n",
    "# Get the loaded model info via Pelion...\n",
    "reload_result = my_notebook.pelion_api.pelion_list_models();\n",
    "print(reload_result)\n",
    "if 'response' in reload_result and len(reload_result['response']) > 0:\n",
    "    if 'name' in reload_result['response'][0]:\n",
    "        print(\"\")\n",
    "        print(\"Currently Loaded Model(s):\")\n",
    "        print(reload_result)\n",
    "else:\n",
    "    print(\"Model: \" + model_name + \" did NOT load properly. Check sagemaker edge agent logs on GW.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the loaded model info via Pelion...\n",
    "reload_result = my_notebook.pelion_api.pelion_list_models();\n",
    "print(reload_result)\n",
    "if 'response' in reload_result and len(reload_result['response']) > 0:\n",
    "    if 'name' in reload_result['response'][0]:\n",
    "        print(\"\")\n",
    "        print(\"Currently Loaded Model(s):\")\n",
    "        print(reload_result)\n",
    "else:\n",
    "    print(\"Model: \" + model_name + \" did NOT load properly. Check sagemaker edge agent logs on GW.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a manual invocation first to \"prime\" the compiled model - first run is always slow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input images directory in our notebook...\n",
    "image_paths = './images'\n",
    "\n",
    "# collect and prepare our images to analyze\n",
    "print(\"\")\n",
    "print(\"Collecting images from: \" + str(image_paths))\n",
    "my_image_list = [os.path.join(image_paths,filename) for filename in os.listdir(image_paths) if os.path.isfile(image_paths + '/' + filename)]\n",
    "my_image_list_length = len(my_image_list)\n",
    "\n",
    "# Display the input image set\n",
    "print(\"\")\n",
    "print(\"Input Image Files: \" + json.dumps(my_image_list))\n",
    "\n",
    "# read in the batch of images... then, preprocess_input() is ResNet50 specific\n",
    "print(\"\")\n",
    "print(\"Pre-processing input image files...\")\n",
    "image_data = my_notebook.read_image_batch(my_image_list, image_size_h, image_size_w)\n",
    "preprocessed_images_list = preprocess_input(image_data['array'])\n",
    "\n",
    "# Display our initial images\n",
    "print(\"\")\n",
    "print(\"Displaying Input Images:\")\n",
    "my_notebook.display_images(image_data['img'])\n",
    "\n",
    "#\n",
    "# Neo Sagemaker likes NCHW shapes for Keras models. \n",
    "# Our image set is in NHWC...\n",
    "#\n",
    "print(\"\")\n",
    "print(\"Input shape: \" + str(preprocessed_images_list.shape))\n",
    "print(\"Input dtype: \" + str(preprocessed_images_list.dtype))\n",
    "print(\"Input data length number of images: \" + str(len(preprocessed_images_list)))\n",
    "\n",
    "# ...so transpose() to NCHW format...  we have to do this because Neo requires a NCHW layer...\n",
    "preprocessed_images_list = tf.transpose(preprocessed_images_list,[0, 3, 1, 2])\n",
    "\n",
    "# Neo-compatible input tensor shape now!\n",
    "print(\"\")\n",
    "print(\"Neo transposed Input shape: \" + str(preprocessed_images_list.shape))\n",
    "print(\"Neo transposed Input dtype: \" + str(preprocessed_images_list.dtype))\n",
    "print(\"Neo transposed Input data length number of images: \" + str(len(preprocessed_images_list)))\n",
    "\n",
    "# Save the preprocessed images, as the input tensor, to a single input file in S3\n",
    "input_data_filename = 'preprocessed_images_' + str(time.time()) + '.input'\n",
    "my_notebook.save_input_tensor_to_s3(preprocessed_images_list,input_data_filename)\n",
    "\n",
    "# Invoke the prediction with our input image data via Pelion using the S3 URLs for input and outputs...\n",
    "input_tensor_s3 = 's3:///' + input_data_filename\n",
    "output_tensor_s3 = 's3:///' + model_basename + '-predicted.data'\n",
    "print(\"Invoking Prediction on Pelion Edge with Sagemaker. Model: \" + model_name + \" Input Tensor: \" + input_tensor_s3 + \" Output Tensor: \" + output_tensor_s3)\n",
    "print(\"\")\n",
    "my_notebook.pelion_api.pelion_predict(model_name, input_tensor_s3, output_tensor_s3)\n",
    "\n",
    "# Poll every busy_loop_wait_time_sec seconds to look for the predict() completion....\n",
    "while True:\n",
    "    print('Predicting...')\n",
    "    is_running = my_notebook.pelion_api.pelion_cmd_is_running(\"predict\");\n",
    "    if is_running == False:\n",
    "        print(\"\")\n",
    "        print('Prediction Completed!')\n",
    "        print(\"\")\n",
    "        break\n",
    "    time.sleep(busy_loop_wait_time_sec)\n",
    "    \n",
    "# Now get the prediction result\n",
    "prediction_result = my_notebook.pelion_api.pelion_last_cmd_result();\n",
    "if 'details' in prediction_result:\n",
    "    if 'output' in prediction_result['details']:\n",
    "        print(\"\")\n",
    "        print(\"Prediction Results:\")\n",
    "        print(prediction_result)\n",
    "        \n",
    "# Prediction results tensor filename in our notebook\n",
    "output_tensor_local_nb_filename = model_basename + '-prediction-output.tensor'\n",
    "\n",
    "# Read the output tensor from S3 and deposit a copy of the output into the notebook. our output tensor should be float32 for Resnet50...\n",
    "output_tensor = my_notebook.get_output_tensor(prediction_result['details']['output'][0]['url'], output_tensor_local_nb_filename, np.float32)\n",
    "\n",
    "# Decode the Resnet50 prediction results\n",
    "print(\"\")\n",
    "print(\"Decoding ResNet50 Imagenet-trained Prediction results...\")\n",
    "most_likely_labels = my_notebook.decode_resnet50_predictions(output_tensor, top=3, class_list_path=resnet50_class_list_path)\n",
    "\n",
    "# Display the images, annotated with the predictions\n",
    "print(\"\")\n",
    "print(\"Displaying prediction results...\")\n",
    "my_notebook.display_images(image_data['img'],most_likely_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we startup our video capture loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Starting video capture...\")\n",
    "my_notebook.pelion_api.pelion_start_videocapture(True)\n",
    "print(\"Video capture started.\")\n",
    "time.sleep(vp_initial_sleep_sec)\n",
    "\n",
    "# Loop and pull over the captured images and display our preditions\n",
    "counter = 1\n",
    "while True:\n",
    "    try:\n",
    "        # pull over the latest images\n",
    "        print(\"\")\n",
    "        print(\"Getting latest capture timestamps...\")\n",
    "        timestamps = my_notebook.pull_video_captures()\n",
    "        print(\"Retrieved \" + str(len(timestamps)) + \" timestamps...\")\n",
    "        if len(timestamps) > 0:\n",
    "            for timestamp in timestamps:\n",
    "                # Read in images for the ith timestamp\n",
    "                print(\"\")\n",
    "                print(\"Calling read_captured_images...\")\n",
    "                image_list = my_notebook.read_captured_images(timestamp,image_size_w,image_size_h)\n",
    "                if not image_list is None:\n",
    "                    # Read in the output tensor and decode the predictions\n",
    "                    print(\"\")\n",
    "                    print(\"Calling get_captured_output_tensor...\")\n",
    "                    output_tensor = my_notebook.get_captured_output_tensor(timestamp, np.float32)\n",
    "                    if not output_tensor is None:\n",
    "                        # Display the ith set of images and our predictions\n",
    "                        print(\"\")\n",
    "                        print(\"Displaying captured predictions for Timestamp: \" + timestamp)\n",
    "                        my_notebook.display_captures(image_list, output_tensor, timestamp, resnet50_class_list_path)\n",
    "                    else:\n",
    "                        print(\"\")\n",
    "                        print(\"Ignoring timestamp: \" + str(timestamp) + \" (no output prediction)... OK.\")\n",
    "                else:\n",
    "                    print(\"\")\n",
    "                    print(\"Ignoring timestamp: \" + str(timestamp) + \" (image read incomplete)... OK.\")\n",
    "        else:\n",
    "            print(\"\")\n",
    "            print(\"No timestamps given\")\n",
    "    except Exception as e:\n",
    "        print(\"\")\n",
    "        print(\"Exception occurred during capture parsing...\")\n",
    "        print(e)\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)\n",
    "                \n",
    "    # Pause for a bit...\n",
    "    print(\"\")\n",
    "    print(\"Sleeping for a few seconds... count: \" + str(counter))\n",
    "    time.sleep(vp_loop_sleep_sec)\n",
    "    \n",
    "    # Clean up if we have timestamps...\n",
    "    if len(timestamps) > 0:\n",
    "        for timestamp in timestamps:\n",
    "            print(\"\")\n",
    "            print(\"Cleaning out captures for timestamp: \" + timestamp)\n",
    "            my_notebook.clean_captures(timestamp, vp_clear_s3, vp_clear_nb)\n",
    "\n",
    "    # increment and clear the output section...\n",
    "    counter = counter + 1\n",
    "    time.sleep(vp_clean_sleep_sec)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At any time we can interrupt the video capture loop and tell our capture PT to stop collecting captures..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop video capture...\n",
    "print(\"\")\n",
    "print(\"Stopping video capture...\")\n",
    "my_notebook.pelion_api.pelion_stop_videocapture()\n",
    "\n",
    "# Finalize cleanup if we have timestamps...\n",
    "print(\"\")\n",
    "print(\"Cleaning up last video captures\")\n",
    "time.sleep(vp_clean_sleep_sec)\n",
    "my_notebook.finalize_clean_captures(vp_clear_s3, vp_clear_nb)\n",
    "time.sleep(vp_clean_sleep_sec)\n",
    "my_notebook.finalize_clean_captures(vp_clear_s3, vp_clear_nb)\n",
    "print(\"\")\n",
    "print(\"Video capture stopped! Captures cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
